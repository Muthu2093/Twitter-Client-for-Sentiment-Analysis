activityLevel <- gsub("Level 5","#FFFFBF", activityLevel)
activityLevel <- gsub("Level 4","#D9EF8B", activityLevel)
activityLevel <- gsub("Level 3","#A6D96A", activityLevel)
activityLevel <- gsub("Level 2","#66BD63", activityLevel)
activityLevel <- gsub("Level 1","#1A9850", activityLevel)
activityLevel <- gsub("Level 0","#006837", activityLevel)
df_activityLevel=data.frame(activityLevel)
#heatmap(df_activityLevel(,1))
#df <- melt(data.frame(data$STATENAME, data$ACTIVITY.LEVEL, activityLevel))
library(fiftystater)
library(RColorBrewer)
display.brewer.all()
map(database = 'state',regions=data$STATENAME,  fill=TRUE, col=activityLevel,
resolution=0)
#heatmap colors()
#fiftystates
View(data)
states
rm(list =ls())
library(maps)
setwd("/Users/muthuvel/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Scripts")
data <- read.csv("../Data/Heat Map/heatmap.csv")
states=data$STATENAME
activityLevel <- data$ACTIVITY.LEVEL
activityLevel <- gsub("Level 10","#A50026", activityLevel)
activityLevel <- gsub("Level 9","#D73027", activityLevel)
activityLevel <- gsub("Level 8","#F46D43", activityLevel)
activityLevel <- gsub("Level 7","#FDAE61", activityLevel)
activityLevel <- gsub("Level 6","#FEE08B", activityLevel)
activityLevel <- gsub("Level 5","#FFFFBF", activityLevel)
activityLevel <- gsub("Level 4","#D9EF8B", activityLevel)
activityLevel <- gsub("Level 3","#A6D96A", activityLevel)
activityLevel <- gsub("Level 2","#66BD63", activityLevel)
activityLevel <- gsub("Level 1","#1A9850", activityLevel)
activityLevel <- gsub("Level 0","#006837", activityLevel)
df_activityLevel=data.frame(activityLevel)
#heatmap(df_activityLevel(,1))
#df <- melt(data.frame(data$STATENAME, data$ACTIVITY.LEVEL, activityLevel))
library(fiftystater)
library(RColorBrewer)
display.brewer.all()
map(database = 'state',regions=data$STATENAME,  fill=TRUE, col=activityLevel,
resolution=0)
#heatmap colors()
#fiftystates
rm(list =ls())
library(maps)
setwd("/Users/muthuvel/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Scripts")
data <- read.csv("../Data/Heat Map/heatmap.csv")
states=data$STATENAME
activityLevel <- data$ACTIVITY.LEVEL
View(data)
rm(list =ls())
library(maps)
setwd("/Users/muthuvel/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Scripts")
data <- read.csv("../Data/Heat Map/heatmap.csv")
states=data$STATENAME
activityLevel <- data$ACTIVITY.LEVEL
activityLevel <- gsub("Level 10","#A50026", activityLevel)
activityLevel <- gsub("Level 9","#D73027", activityLevel)
activityLevel <- gsub("Level 8","#F46D43", activityLevel)
activityLevel <- gsub("Level 7","#FDAE61", activityLevel)
activityLevel <- gsub("Level 6","#FEE08B", activityLevel)
activityLevel <- gsub("Level 5","#FFFFBF", activityLevel)
activityLevel <- gsub("Level 4","#D9EF8B", activityLevel)
activityLevel <- gsub("Level 3","#A6D96A", activityLevel)
activityLevel <- gsub("Level 2","#66BD63", activityLevel)
activityLevel <- gsub("Level 1","#1A9850", activityLevel)
activityLevel <- gsub("Level 0","#006837", activityLevel)
df_activityLevel=data.frame(activityLevel)
#heatmap(df_activityLevel(,1))
#df <- melt(data.frame(data$STATENAME, data$ACTIVITY.LEVEL, activityLevel))
library(fiftystater)
library(RColorBrewer)
display.brewer.all()
map(database = 'state',regions=data$STATENAME,  fill=TRUE, col=activityLevel,
resolution=0)
#heatmap colors()
#fiftystates
library(maps)
setwd("/Users/muthuvel/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Scripts")
data <- read.csv("../Data/Heat Map/heatmap.csv")
states=data$STATENAME
activityLevel <- data$ACTIVITY.LEVEL
states
activityLevel
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
setwd("../data_collected")
setwd("~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
View(location_GeoCode)
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
min(location_GeoCode[,2])
View(location_GeoCode)
min(location_GeoCode[,2])
min(location_GeoCode[,1])
min(location_GeoCode$lon)
min(location_GeoCode$lat])
min(location_GeoCode$lat)
View(location_GeoCode)
library(RgoogleMaps)
#lat <- c(-38.31, -35.50) #define our map's ylim
#lon <- c(40.96,37.50) #define our map's xlim
center = c(mean(location_GeoCode$lat), mean(location_GeoCode$lon))  #tell what point to center on
zoom <- 2 #zoom: 1 = furthest out (entire globe), larger numbers = closer in
terrmap <- GetMap(center=center, zoom=zoom, maptype= "satallite", destfile = "satallite.png")
# loading the required packages
library(ggplot2)
library(ggmap)
# creating a sample data.frame with your lat/lon points
lon <- c(66.57,124.46)
lat <- c(49.23, 24.31)
df <- as.data.frame(cbind(lon,lat))
# getting the map
mapgilbert <- get_map(location = c(lon = mean(location_GeoCode$lon), lat = mean(location_GeoCode$lat)), zoom = 4,
maptype = "satellite", scale = 2)
# loading the required packages
library(ggplot2)
library(ggmap)
# creating a sample data.frame with your lat/lon points
lon <- c(49.23, 24.31)
lat <- c(66.57,124.46)
df <- as.data.frame(cbind(lon,lat))
# getting the map
mapgilbert <- get_map(location = c(lon = mean(location_GeoCode$lon), lat = mean(location_GeoCode$lat)), zoom = 4,
maptype = "satellite", scale = 2)
View(location_GeoCode)
df <- as.data.frame(cbind(lon,lat))
# loading the required packages
library(ggplot2)
library(ggmap)
# creating a sample data.frame with your lat/lon points
lon <- c(49.23, 24.31)
lat <- c(66.57,124.46)
lon <- c(49.23, 24.31)
lat <- c(66.57,124.46)
df <- as.data.frame(cbind(lon,lat))
# getting the map
mapgilbert <- get_map(location = c(lon = mean(location_GeoCode$lon), lat = mean(location_GeoCode$lat)), zoom = 4,
maptype = "satellite", scale = 2)
View(df)
# loading the required packages
library(ggplot2)
library(ggmap)
# creating a sample data.frame with your lat/lon points
lon <- c(49.34, 24.7433195)
lat <- c(-124.7844079,-66.9513812)
df <- as.data.frame(cbind(lon,lat))
# getting the map
mapgilbert <- get_map(location = c(lon = mean(location_GeoCode$lon), lat = mean(location_GeoCode$lat)), zoom = 4,
maptype = "satellite", scale = 2)
# creating a sample data.frame with your lat/lon points
lat <- c(49.34, 24.7433195)
lon <- c(-124.7844079,-66.9513812)
df <- as.data.frame(cbind(lon,lat))
# getting the map
mapgilbert <- get_map(location = c(lon = mean(location_GeoCode$lon), lat = mean(location_GeoCode$lat)), zoom = 4,
maptype = "satellite", scale = 2)
meanl <- mean(location_GeoCode$lon)
meant <- mean(location_GeoCode$lat)
# getting the map
mapgilbert <- get_map(location = c(meanl, meant), zoom = 4,
maptype = "satellite", scale = 2)
meanl <- sum(..., na.rm = FALSE)/11441
meanl <- sum(location_GeoCode$lon)
location_GeoCode$lon
# getting the map
mapgilbert <- get_map(location = c(39.50, 98.00), zoom = 4,
maptype = "satellite", scale = 2)
# getting the map
mapgilbert <- get_map(location = c(39.50, -98.00), zoom = 4,
maptype = "satellite", scale = 2)
View(location_GeoCode)
# getting the map
mapgilbert <- get_map(location = c(40.00,-70.00), zoom = 4,
maptype = "satellite", scale = 2)
# plotting the map with some points on it
ggmap(mapgilbert) +
geom_point(data = df, aes(x = lon, y = lat, fill = "red", alpha = 0.8), size = 5, shape = 21) +
guides(fill=FALSE, alpha=FALSE, size=FALSE)
install.packages("ggproto")
ggproto("GeomRasterAnn")
ggproto("ggplot2", dependencies=TRUE)
install.packages("ggplot2", dependencies=TRUE)
install.packages("ggplot2", dependencies = TRUE)
install.packages("zipcode")
library(zipcode)
DF= data(zipcode)
View(df)
library(zipcode)
DF= data(zipcode)
View(zipcode)
library(zipcode)
data(zipcode)
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
View(location_GeoCode)
View(zipcode)
valid_US_locationGeocode <- subset(location_Geocode,
location_Geocode$lat >=24.00 |
location_Geocode$lat <=51.00 |
location_Geocode$lon >=-125.00 |
location_Geocode$lat <=-66.00)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 |
location_GeoCode$lat <=51.00 |
location_GeoCode$lon >=-125.00 |
location_GeoCode$lat <=-66.00)
View(valid_US_locationGeocode)
library(zipcode)
data(zipcode)
## lat low = 24.oo, high =  50
## long low = -125.00, high = -66
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 |
location_GeoCode$lat <=24.00 |
location_GeoCode$lon >=-125.00 |
location_GeoCode$lat <=-66.00)
View(valid_US_locationGeocode)
View(valid_US_locationGeocode)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 &&
location_GeoCode$lat <=51.00 &&
location_GeoCode$lon >=-125.00 &&
location_GeoCode$lat <=-66.00)
View(location_GeoCode)
library(zipcode)
data(zipcode)
## lat low = 24.oo, high =  50
## long low = -125.00, high = -66
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 &
location_GeoCode$lat <=51.00 &
location_GeoCode$lon >=-125.00 &
location_GeoCode$lat <=-66.00)
View(location_GeoCode)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 &
location_GeoCode$lat <=51.00 &
location_GeoCode$lon >=-125.00 &
location_GeoCode$lat <=-66.00)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 )
#location_GeoCode$lat <=51.00 &
#location_GeoCode$lon >=-125.00 &
#location_GeoCode$lat <=-66.00)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat <=51.00)
View(location_GeoCode)
library(zipcode)
data(zipcode)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 )
valid_US_locationGeocode <- subset(valid_US_locationGeocode,
valid_US_locationGeocode$lat <=51.00)
valid_US_locationGeocode <- subset(valid_US_locationGeocode,
valid_US_locationGeocode$lon >=-125.00)
valid_US_locationGeocode <- subset(valid_US_locationGeocode,
valid_US_locationGeocode$lat <=-66.00)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 )
valid_US_locationGeocode <- subset(valid_US_locationGeocode,
valid_US_locationGeocode$lat <=51.00)
valid_US_locationGeocode <- subset(valid_US_locationGeocode,
valid_US_locationGeocode$lon >=-125.00)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 )
location_GeoCode$lat <=51.00 &
location_GeoCode$lon >=-125.00 &
location_GeoCode$lon <=-66.00)
View(valid_US_locationGeocode)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 &
location_GeoCode$lat <=51.00 &
location_GeoCode$lon >=-125.00 &
location_GeoCode$lat <=-66.00)
valid_US_locationGeocode <- subset(location_GeoCode,
location_GeoCode$lat >=24.00 &
location_GeoCode$lat <=51.00 &
location_GeoCode$lon >=-125.00 &
location_GeoCode$lon <=-66.00)
View(valid_US_locationGeocode)
valid_US_locationGeocode1 <- subset(location_GeoCode,
location_GeoCode$lon == zipcode$longitude)
View(zipcode)
install.packages("daff")
library(zipcode)
library(daff)
View(valid_US_locationGeocode)
View(zipcode)
View(valid_US_locationGeocode)
ll <- cbind(zipcode$longitude,zipcode$latitude)
ll <- data.frame(ll)
View(ll)
names(ll)[1] <- "lon"
View(zipcode)
View(ll)
valid_lat <- diff_data(ll$lat, location_GeoCode)
valid_lat <- diff_data(ll$lat, location_GeoCode$lat)
valid_lat <- diff_data(ll$lat, location_GeoCode$lat, always_show_header = TRUE,
always_show_order = FALSE)
rm(list =ls())
#### SET THE WORKING DIRECTORY TO 'SCRIPTS' FOLDER IN LAB1 PART3 BEFORE RUNNING THE SCRIPT####
## loading libraries
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Setup oauth
setup_twitter_oauth("VxJ6qp5XL3VTclBzMBsD1Ez1A", "owezT5IVRVG8nvkSHXxqq4t2McwPO6mxesJTGU2549yHTJbP8m", "340449785-0AWt3nkBVvLlX7hbUFLl0fEqIKs47qUU7V5UnFWH", "qnaD0Pyp9jUXfwVb82RlSKikuvVi2MAWxp1J0mD1Fle4d")
############## Collection of Tweets ###################
## Searching for tweets ##
search.string <- "#flu"
no.of.tweets <- 1300
tweets <- searchTwitter(search.string, n=no.of.tweets, lang="en")
## Conversion of searched tweets to Data frame
tweets <- twListToDF(tweets)
## Saving collected data to a csv file - only the tweets collection this session
setwd("../data_collected")
Name=paste("New", no.of.tweets," Tweets Collected on ",Sys.time())
write.csv(tweets, file = Name)
setwd("../Scripts")
# Reading all tweets collected so far
CDF=read.csv("../data_collected/consolidated_Tweets_Total")
CDF<- subset(CDF, select = -c(X)) #removing column named X
# Creating a consolided data frame of all the tweets collected so far
consolidated_Tweets_Total=rbind(CDF,tweets)
consolidated_Tweets_Total <- unique( consolidated_Tweets_Total[ , 1:16 ] ) #remove duplicates
# Saving all Tweets Collected from day 1 to csv file
setwd("../data_collected")
write.csv(consolidated_Tweets_Total, file = "consolidated_Tweets_Total")
setwd("../Scripts")
################# Filtering Tweets ####################
## Eliminating duplicate users by lookingUp screenName
usernames <- tweets$screenName
temp_df <- twListToDF(lookupUsers(usernames))
## Remove users without any location information
DWL=read.csv("../data_collected/data_With_location")
DWL<- subset(DWL, select = -c(X)) #removing column named X
tweets_With_location <- subset(temp_df, temp_df$location != "")
data_With_location <- rbind(DWL, tweets_With_location)
data_With_location <- unique( data_With_location[ , 1:17 ] )
#Saving the data with location to csv file
setwd("../data_collected")
write.csv(data_With_location, file = "data_With_location")
setwd("../Scripts")
########################## Fetching Geocode of users #######################
## Code to access geocode - limit 2500 per day - dont waste it
## Use it after you have extracted tweets with location info (20 to 30 maybe)
# locatedUsers <- !is.na(tweets_with_location$location)
j<-1;
for (i in tweets_With_location$location){
loc <- i
if (stringi::stri_enc_mark(loc)=="ASCII"){
if (j==1){
locations <- geocode(loc)
}
if (j>1){
locations <- rbind(locations,geocode(loc))
}
j <- j+1
}
}
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
location_GeoCode <- rbind(location_GeoCode,locations)
location_GeoCode <- subset(location_GeoCode, location_GeoCode$lon != "")
write.csv(location_GeoCode, file = "location_GeoCode")
setwd("../Scripts")
rm(list =ls())
#### SET THE WORKING DIRECTORY TO 'SCRIPTS' FOLDER IN LAB1 PART3 BEFORE RUNNING THE SCRIPT####
## loading libraries
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Setup oauth
setup_twitter_oauth("VxJ6qp5XL3VTclBzMBsD1Ez1A", "owezT5IVRVG8nvkSHXxqq4t2McwPO6mxesJTGU2549yHTJbP8m", "340449785-0AWt3nkBVvLlX7hbUFLl0fEqIKs47qUU7V5UnFWH", "qnaD0Pyp9jUXfwVb82RlSKikuvVi2MAWxp1J0mD1Fle4d")
############## Collection of Tweets ###################
## Searching for tweets ##
search.string <- "#flu"
no.of.tweets <- 1300
tweets <- searchTwitter(search.string, n=no.of.tweets, lang="en")
## Conversion of searched tweets to Data frame
tweets <- twListToDF(tweets)
## Saving collected data to a csv file - only the tweets collection this session
setwd("../data_collected")
Name=paste("New", no.of.tweets," Tweets Collected on ",Sys.time())
write.csv(tweets, file = Name)
setwd("../Scripts")
# Reading all tweets collected so far
CDF=read.csv("../data_collected/consolidated_Tweets_Total")
CDF<- subset(CDF, select = -c(X)) #removing column named X
# Creating a consolided data frame of all the tweets collected so far
consolidated_Tweets_Total=rbind(CDF,tweets)
consolidated_Tweets_Total <- unique( consolidated_Tweets_Total[ , 1:16 ] ) #remove duplicates
# Saving all Tweets Collected from day 1 to csv file
setwd("../data_collected")
write.csv(consolidated_Tweets_Total, file = "consolidated_Tweets_Total")
setwd("../Scripts")
################# Filtering Tweets ####################
## Eliminating duplicate users by lookingUp screenName
usernames <- tweets$screenName
temp_df <- twListToDF(lookupUsers(usernames))
## Remove users without any location information
DWL=read.csv("../data_collected/data_With_location")
DWL<- subset(DWL, select = -c(X)) #removing column named X
tweets_With_location <- subset(temp_df, temp_df$location != "")
data_With_location <- rbind(DWL, tweets_With_location)
data_With_location <- unique( data_With_location[ , 1:17 ] )
#Saving the data with location to csv file
setwd("../data_collected")
write.csv(data_With_location, file = "data_With_location")
setwd("../Scripts")
########################## Fetching Geocode of users #######################
## Code to access geocode - limit 2500 per day - dont waste it
## Use it after you have extracted tweets with location info (20 to 30 maybe)
# locatedUsers <- !is.na(tweets_with_location$location)
j<-1;
for (i in tweets_With_location$location){
loc <- i
if (stringi::stri_enc_mark(loc)=="ASCII"){
if (j==1){
locations <- geocode(loc)
}
if (j>1){
locations <- rbind(locations,geocode(loc))
}
j <- j+1
}
}
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
location_GeoCode <- rbind(location_GeoCode,locations)
location_GeoCode <- subset(location_GeoCode, location_GeoCode$lon != "")
write.csv(location_GeoCode, file = "location_GeoCode")
setwd("../Scripts")
geocodeQueryCheck()
rm(list =ls())
#### SET THE WORKING DIRECTORY TO 'SCRIPTS' FOLDER IN LAB1 PART3 BEFORE RUNNING THE SCRIPT####
## loading libraries
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Setup oauth
setup_twitter_oauth("VxJ6qp5XL3VTclBzMBsD1Ez1A", "owezT5IVRVG8nvkSHXxqq4t2McwPO6mxesJTGU2549yHTJbP8m", "340449785-0AWt3nkBVvLlX7hbUFLl0fEqIKs47qUU7V5UnFWH", "qnaD0Pyp9jUXfwVb82RlSKikuvVi2MAWxp1J0mD1Fle4d")
############## Collection of Tweets ###################
## Searching for tweets ##
search.string <- "#flu"
no.of.tweets <- 1300
tweets <- searchTwitter(search.string, n=no.of.tweets, lang="en")
## Conversion of searched tweets to Data frame
tweets <- twListToDF(tweets)
## Saving collected data to a csv file - only the tweets collection this session
setwd("../data_collected")
Name=paste("New", no.of.tweets," Tweets Collected on ",Sys.time())
write.csv(tweets, file = Name)
setwd("../Scripts")
# Reading all tweets collected so far
CDF=read.csv("../data_collected/consolidated_Tweets_Total")
CDF<- subset(CDF, select = -c(X)) #removing column named X
# Creating a consolided data frame of all the tweets collected so far
consolidated_Tweets_Total=rbind(CDF,tweets)
consolidated_Tweets_Total <- unique( consolidated_Tweets_Total[ , 1:16 ] ) #remove duplicates
# Saving all Tweets Collected from day 1 to csv file
setwd("../data_collected")
write.csv(consolidated_Tweets_Total, file = "consolidated_Tweets_Total")
setwd("../Scripts")
################# Filtering Tweets ####################
## Eliminating duplicate users by lookingUp screenName
usernames <- tweets$screenName
temp_df <- twListToDF(lookupUsers(usernames))
## Remove users without any location information
DWL=read.csv("../data_collected/data_With_location")
DWL<- subset(DWL, select = -c(X)) #removing column named X
tweets_With_location <- subset(temp_df, temp_df$location != "")
data_With_location <- rbind(DWL, tweets_With_location)
data_With_location <- unique( data_With_location[ , 1:17 ] )
#Saving the data with location to csv file
setwd("../data_collected")
write.csv(data_With_location, file = "data_With_location")
setwd("../Scripts")
########################## Fetching Geocode of users #######################
## Code to access geocode - limit 2500 per day - dont waste it
## Use it after you have extracted tweets with location info (20 to 30 maybe)
# locatedUsers <- !is.na(tweets_with_location$location)
j<-1;
for (i in tweets_With_location$location){
loc <- i
if (stringi::stri_enc_mark(loc)=="ASCII"){
if (j==1){
locations <- geocode(loc)
}
if (j>1){
locations <- rbind(locations,geocode(loc))
}
j <- j+1
}
}
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
location_GeoCode <- rbind(location_GeoCode,locations)
location_GeoCode <- subset(location_GeoCode, location_GeoCode$lon != "")
write.csv(location_GeoCode, file = "location_GeoCode")
setwd("../Scripts")
