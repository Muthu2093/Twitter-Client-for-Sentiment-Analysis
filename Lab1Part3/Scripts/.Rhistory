<<<<<<< Updated upstream
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
i=i+1
## Storing the last index of reverserGeocode to set the starting point of next query
setwd("../data_collected")
write.csv(data.frame(i), file = "index")
setwd("../Scripts")
## Reading the states extracted from reverse_geocode  so far
setwd("../data_collected")
statesFrequency <- read.csv("../data_collected/statesFrequency")
statesFrequency<- subset(statesFrequency, select = -c(X)) #removing column named X
setwd("../Scripts")
## Writing the conslidated states to csv file
statesFrequency = rbind(statesFrequency,states)
setwd("../data_collected")
write.csv(statesFrequency, file = "statesFrequency")
setwd("../Scripts")
## Reverse Geocoding for extracting the states names for heatmap from the tweets gathered
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
for (i in start:end)
{
# print(i)
# Checking if we are exceeding the dimension of tweet input DF
if (i>=nrow(location_GeoCode))
{
i=i-1
break
}
a <- data.frame(revgeocode(as.numeric(location_GeoCode[i,]),output = c("more"), override_limit = TRUE))
#if (is.na(a))
#{
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
i=i+1
## Storing the last index of reverserGeocode to set the starting point of next query
setwd("../data_collected")
write.csv(data.frame(i), file = "index")
setwd("../Scripts")
## Reading the states extracted from reverse_geocode  so far
setwd("../data_collected")
statesFrequency <- read.csv("../data_collected/statesFrequency")
statesFrequency<- subset(statesFrequency, select = -c(X)) #removing column named X
setwd("../Scripts")
## Writing the conslidated states to csv file
statesFrequency = rbind(statesFrequency,states)
setwd("../data_collected")
write.csv(statesFrequency, file = "statesFrequency")
setwd("../Scripts")
## Reverse Geocoding for extracting the states names for heatmap from the tweets gathered
library(twitteR)
=======
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
p <- ggplot(temp, aes(map_id = state)) +
geom_map(aes(fill = count), map = fifty_states, color = "black") +
expand_limits(x = fifty_states$long, y = fifty_states$lat) +
coord_map() +
scale_color_brewer(palette = "Spectral") +
#scale_fill_gradient2(low="red2", mid = "green", high="yellow") +
scale_x_continuous(breaks = NULL) +
scale_y_continuous(breaks = NULL) +
labs(x = "", y = "") +
ggtitle("2017-18 Influenza Season Week 4 ending Jan 27, 2018") +
theme(legend.position = "right",
plot.title = element_text(family = "Helvetica Neue", color="#666666", face="bold", size=12, hjust=0))
print(p + ggtitle("HeatMap of Tweets on Influenza in USA"))
# add border boxes to AK/HI
p + fifty_states_inset_boxes()
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
View(fifty_states)
View(temp)
>>>>>>> Stashed changes
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
for (i in start:end)
{
# print(i)
# Checking if we are exceeding the dimension of tweet input DF
if (i>=nrow(location_GeoCode))
{
i=i-1
break
}
a <- data.frame(revgeocode(as.numeric(location_GeoCode[i,]),output = c("more"), override_limit = TRUE))
#if (is.na(a))
#{
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
i=i+1
## Storing the last index of reverserGeocode to set the starting point of next query
setwd("../data_collected")
write.csv(data.frame(i), file = "index")
setwd("../Scripts")
## Reading the states extracted from reverse_geocode  so far
setwd("../data_collected")
statesFrequency <- read.csv("../data_collected/statesFrequency")
statesFrequency<- subset(statesFrequency, select = -c(X)) #removing column named X
setwd("../Scripts")
## Writing the conslidated states to csv file
statesFrequency = rbind(statesFrequency,states)
setwd("../data_collected")
write.csv(statesFrequency, file = "statesFrequency")
setwd("../Scripts")
## Reverse Geocoding for extracting the states names for heatmap from the tweets gathered
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
for (i in start:end)
{
# print(i)
# Checking if we are exceeding the dimension of tweet input DF
if (i>=nrow(location_GeoCode))
{
i=i-1
break
}
a <- data.frame(revgeocode(as.numeric(location_GeoCode[i,]),output = c("more"), override_limit = TRUE))
#if (is.na(a))
#{
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
i=i+1
## Storing the last index of reverserGeocode to set the starting point of next query
setwd("../data_collected")
write.csv(data.frame(i), file = "index")
setwd("../Scripts")
## Reading the states extracted from reverse_geocode  so far
setwd("../data_collected")
statesFrequency <- read.csv("../data_collected/statesFrequency")
statesFrequency<- subset(statesFrequency, select = -c(X)) #removing column named X
setwd("../Scripts")
## Writing the conslidated states to csv file
statesFrequency = rbind(statesFrequency,states)
setwd("../data_collected")
write.csv(statesFrequency, file = "statesFrequency")
setwd("../Scripts")
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
for (i in start:end)
{
# print(i)
# Checking if we are exceeding the dimension of tweet input DF
if (i>=nrow(location_GeoCode))
{
i=i-1
break
}
a <- data.frame(revgeocode(as.numeric(location_GeoCode[i,]),output = c("more"), override_limit = TRUE))
#if (is.na(a))
#{
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
## Reverse Geocoding for extracting the states names for heatmap from the tweets gathered
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
for (i in start:end)
{
# print(i)
# Checking if we are exceeding the dimension of tweet input DF
if (i>=nrow(location_GeoCode))
{
i=i-1
break
}
a <- data.frame(revgeocode(as.numeric(location_GeoCode[i,]),output = c("more"), override_limit = TRUE))
#if (is.na(a))
#{
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
i=i+1
## Reverse Geocoding for extracting the states names for heatmap from the tweets gathered
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
## Reverse Geocoding for extracting the states names for heatmap from the tweets gathered
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
for (i in start:end)
{
# print(i)
# Checking if we are exceeding the dimension of tweet input DF
if (i>=nrow(location_GeoCode))
{
i=i-1
break
}
a <- data.frame(revgeocode(as.numeric(location_GeoCode[i,]),output = c("more"), override_limit = TRUE))
#if (is.na(a))
#{
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
i=i+1
## Storing the last index of reverserGeocode to set the starting point of next query
setwd("../data_collected")
write.csv(data.frame(i), file = "index")
setwd("../Scripts")
## Reading the states extracted from reverse_geocode  so far
setwd("../data_collected")
statesFrequency <- read.csv("../data_collected/statesFrequency")
statesFrequency<- subset(statesFrequency, select = -c(X)) #removing column named X
setwd("../Scripts")
## Writing the conslidated states to csv file
statesFrequency = rbind(statesFrequency,states)
setwd("../data_collected")
write.csv(statesFrequency, file = "statesFrequency")
setwd("../Scripts")
## Reverse Geocoding for extracting the states names for heatmap from the tweets gathered
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Reading the tweet collected so far
setwd("../data_collected")
location_GeoCode <- read.csv("../data_collected/location_GeoCode")
location_GeoCode<- subset(location_GeoCode, select = -c(X)) #removing column named X
setwd("../Scripts")
## Reading the starting index of query
setwd("../data_collected")
index <- read.csv("../data_collected/index")
index <- subset(index, select = -c(X)) #removing column named X
setwd("../Scripts")
indicator <- 0
start=index$i[1]
end=index$i[1]+2500
for (i in start:end)
{
# print(i)
# Checking if we are exceeding the dimension of tweet input DF
if (i>=nrow(location_GeoCode))
{
i=i-1
break
}
a <- data.frame(revgeocode(as.numeric(location_GeoCode[i,]),output = c("more"), override_limit = TRUE))
#if (is.na(a))
#{
#  next
#}
temp <- data.frame(a$administrative_area_level_1)
if (indicator == 0)
{
states = temp
indicator <- 1
}
if (indicator != 0)
{
states = rbind(states,temp)
}
}
i=i+1
View(statesFrequency)
rm(list =ls())
library(ggplot2)
Weekly_data<- read.csv("../Data/Number of Influenza-Associated Pediatric Deaths/PedFluDeath_WeeklyData.csv")
rawdata <- Weekly_data
x_axis <- Weekly_data$WEEK.NUMBER[c(6*c(1:32))]
#x_axis=Weekly_data[1:20,]
#x_axis=x_axis[c(2)]
SeasonDeath_data<-read.csv("../Data/Number of Influenza-Associated Pediatric Deaths/Season_Deaths.csv")
Weekly_data <- subset(Weekly_data, select =-c(1))
Data = melt(Weekly_data, id=c("WEEK.NUMBER"))
p<-ggplot(Data,aes(x=WEEK.NUMBER, y=value, fill=variable)) +
geom_bar(stat="identity", position="stack", colour="black") +
scale_fill_manual(name = "Week of Death",
labels = c("Deaths Reported Current Week", "Deaths Reported in Previous Week"),
values = c("CURRENT.WEEK.DEATHS"="cyan", "PREVIOUS.WEEKS.DEATHS"="forestgreen")) +
labs(x="", y="Number of deaths", fill=NULL)
#b<-p+scale_fill_brewer(palette = "Set1")
b<- p+ theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.x=element_text(angle=90, size=8, face="bold", color="black"),
legend.position= "bottom")
b <- b + scale_y_continuous(limit = c(0, 30))+
scale_x_discrete(breaks=x_axis,
labels=x_axis)+
annotate("text", x = 20, y = 20, label = "2014 -2015", size = 4)+
annotate("text", x = 20, y = 19, label = "Number of Deaths Reported = 148", size = 2)+
annotate("text", x = 70, y = 20, label = "2015 -2016", size = 4)+
annotate("text", x = 70, y = 19, label = "Number of Deaths Reported = 93", size = 2)+
annotate("text", x = 120, y = 20, label = "2016 -2017", size = 4)+
annotate("text", x = 120, y = 19, label = "Number of Deaths Reported = 110", size = 2)+
annotate("text", x = 170, y = 20, label = "2017 -2018", size = 4)+
annotate("text", x = 170, y = 19, label = "Number of Deaths Reported = 53", size = 2) +
ggtitle("Number of Influenza-Associated Pediatric Deaths by the Week of Death: 2014-2015 Season to Present")
b
SeasonDeath_data<-read.csv("../Data/Number of Influenza-Associated Pediatric Deaths/Season_Deaths.csv")
setwd("~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Akshay_Scripts")
rm(list =ls())
library(ggplot2)
Weekly_data<- read.csv("../Data/Number of Influenza-Associated Pediatric Deaths/PedFluDeath_WeeklyData.csv")
rawdata <- Weekly_data
x_axis <- Weekly_data$WEEK.NUMBER[c(6*c(1:32))]
SeasonDeath_data<-read.csv("../Data/Number of Influenza-Associated Pediatric Deaths/Season_Deaths.csv")
Weekly_data <- subset(Weekly_data, select =-c(1))
View(SeasonDeath_data)
setwd("~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts")
library(ggplot2)
library(maps)
library(fiftystater)
library(maps)
data <- read.csv("../data_collected/statesFrequency")
data<- subset(data, select = -c(X)) #removing column named X
setwd("../Scripts")
alpha = sort(table(data), decreasing = TRUE)
data("fifty_states")
checker <- data.frame(state.name)
colnames(checker) <- c("state")
rownames <- rownames(alpha)
rownames(alpha) <- NULL
alpha <- data.frame(cbind(rownames,alpha))
colnames(alpha) <- c("state", "count")
pointer = 1
## Code to filter and keep only the 50 - us states(48 continental + Hawaii + Alaska)
for (i in 1:nrow(alpha))
{
for (j in 1:nrow(checker))
{
if (as.character(alpha$state[i])==as.character(checker$state[j]))
{
if (pointer == 1)
{
temp = alpha[i,]
pointer = 2
next
}
if (pointer == 2)
{
temp = rbind(temp,alpha[i,])
}
}
}
}
as.numeric(levels(temp$count))[temp$count]
as.numeric(levels(temp$count))
## Code to filter and keep only the 50 - us states(48 continental + Hawaii + Alaska)
for (i in 1:nrow(alpha))
for (i in 1:nrow(alpha))
{
for (j in 1:nrow(checker))
{
if (as.character(alpha$state[i])==as.character(checker$state[j]))
{
if (pointer == 1)
{
temp = alpha[i,]
pointer = 2
next
}
if (pointer == 2)
{
temp = rbind(temp,alpha[i,])
}
}
}
}
<<<<<<< Updated upstream
=======
## plot heat map
temp$count<-as.numeric(levels(temp$count))[temp$count]
temp$state <- unlist(as.list(tolower(temp$state)))
p <- ggplot(temp, aes(map_id = state)) +
geom_map(aes(fill = count), map = fifty_states, color = "black") +
expand_limits(x = fifty_states$long, y = fifty_states$lat) +
coord_map() +
#scale_color_brewer(palette = "Spectral") +
scale_fill_gradient2(low="yellow", mid = "blue", high="blue") +
scale_x_continuous(breaks = NULL) +
scale_y_continuous(breaks = NULL) +
labs(x = "", y = "") +
ggtitle("2017-18 Influenza Season Week 4 ending Jan 27, 2018") +
theme(legend.position = "right",
plot.title = element_text(family = "Helvetica Neue", color="#666666", face="bold", size=12, hjust=0))
print(p + ggtitle("HeatMap of Tweets on Influenza in USA"))
# add border boxes to AK/HI
p + fifty_states_inset_boxes()
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
p <- ggplot(temp, aes(map_id = state)) +
geom_map(aes(fill = count), map = fifty_states, color = "black") +
expand_limits(x = fifty_states$long, y = fifty_states$lat) +
coord_map() +
#scale_color_brewer(palette = "Spectral") +
scale_fill_gradient2(low="blue", mid="yellow", high="red3", midpoint = 300) +
scale_x_continuous(breaks = NULL) +
scale_y_continuous(breaks = NULL) +
labs(x = "", y = "") +
ggtitle("2017-18 Influenza Season Week 4 ending Jan 27, 2018") +
theme(legend.position = "right",
plot.title = element_text(family = "Helvetica Neue", color="#666666", face="bold", size=12, hjust=0))
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
mean(temp$count)
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
heat.colors(10)
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
setwd("~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts")
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/reverse.R')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/reverse.R')
source('~/Documents/GitHub/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part3/Scripts/plotHeatMapOfTweets.r')
View(alpha)
library(ggplot2)
library(maps)
library(fiftystater)
library(maps)
data <- read.csv("../data_collected/statesFrequency")
data<- subset(data, select = -c(X)) #removing column named X
setwd("../Scripts")
alpha = sort(table(data), decreasing = TRUE)
data("fifty_states")
checker <- data.frame(state.name)
colnames(checker) <- c("state")
rownames <- rownames(alpha)
rownames(alpha) <- NULL
alpha <- data.frame(cbind(rownames,alpha))
colnames(alpha) <- c("state", "count")
pointer = 1
## Code to filter and keep only the 50 - us states(48 continental + Hawaii + Alaska)
for (i in 1:nrow(alpha))
{
for (j in 1:nrow(checker))
{
if (as.character(alpha$state[i])==as.character(checker$state[j]))
{
if (pointer == 1)
{
temp = alpha[i,]
pointer = 2
next
}
if (pointer == 2)
{
temp = rbind(temp,alpha[i,])
}
}
}
}
## plot heat map
temp$count<-as.numeric(levels(temp$count))[temp$count]
temp$state <- unlist(as.list(tolower(temp$state)))
p <- ggplot(temp, aes(map_id = state)) +
geom_map(aes(fill = count), map = fifty_states, color = "black") +
expand_limits(x = fifty_states$long, y = fifty_states$lat) +
coord_map() +
#scale_color_brewer(palette ="Spectral") +
#scale_color_manual(palette = heat.colors(10))
scale_fill_gradient2(low="green", mid="yellow", high="red3", midpoint = mean(temp$count), guides(fill = "Number of Tweets"), limits=c(0,max(temp$count)+100), breaks=c(0,50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000)) +
guides(fill = guide_colorbar(barwidth = 1.5, barheight = 25)) +
scale_x_continuous(breaks = NULL) +
scale_y_continuous(breaks = NULL) +
labs(x = "", y = "") +
ggtitle("2017-18 Influenza Season Week 4 ending Jan 27, 2018") +
theme(legend.position = "right",
plot.title = element_text(family = "Helvetica Neue", color="#666666", face="bold", size=12, hjust=0))
print(p + ggtitle("HeatMap of Tweets on Influenza in USA"))
# add border boxes to AK/HI
p + fifty_states_inset_boxes()
>>>>>>> Stashed changes
